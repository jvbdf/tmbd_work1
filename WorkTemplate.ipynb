{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375aacc5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Técnicas Matemáticas para Big Data - Project NN?\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c68c",
   "metadata": {},
   "source": [
    "GROUP NN:\n",
    "- Student 1 - Nº 106078 - 33.33% Work Participation\n",
    "- Student 2 - Nº xxxxx - ??% Work Participation\n",
    "- Student 3 - Nº xxxxx - ??% Work Participation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fb045",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 1. Introduction to the problem of study [1,0 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2db1f",
   "metadata": {},
   "source": [
    "### Estimating Unique Customers with the HyperLogLog Algorithm\n",
    "\n",
    "We aim to process e-commerce purchase data chronologically, simulating a **data stream** using real sales data obtained from the [Online Retail Dataset – UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/352/online+retail).\n",
    "\n",
    "The dataset contains all transactions that occurred between **01/12/2010 and 09/12/2011** for a **UK-based non-store online retailer**.\n",
    "\n",
    "Each new event (purchase) is added to the data stream, ordered by its corresponding **timestamp**.  \n",
    "The main objective is to **estimate the number of unique customers** who made a purchase in real time.\n",
    "\n",
    "With continuous technological advancements and the ever-growing volume of users and data, companies must monitor customer activities in **real time**. However, the massive amount of data generated requires both **high processing capacity** and **speed**.  \n",
    "\n",
    "Processing data on a large scale is a current technological challenge, as it demands the ability to deliver accurate statistics, analytics, and insights almost instantaneously, without compromising system performance or precision.\n",
    "\n",
    "In this context, the problem addressed focuses on **estimating the number of unique buyers** in an online sales platform as new purchase events continuously arrive.  \n",
    "Each transaction in the dataset represents a sale made by a specific customer at a given moment, allowing us to simulate a **data stream** where events are processed in chronological order.\n",
    "\n",
    "The goal is to estimate, in real time, **how many distinct customers have made purchases** up to any given point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af2342",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 2. Brief and general description of the approach and methods used [1,5 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b7b8d",
   "metadata": {},
   "source": [
    "\n",
    "### Motivation\n",
    "\n",
    "Processing massive amounts of data by storing them in a database and iterating over each record would require **significant computational resources**, making such an approach infeasible.\n",
    "\n",
    "In a traditional setup, counting distinct customers would require storing every `CustomerID` in a database or cache and performing periodic scans as new records arrive.  \n",
    "Although this approach provides exact results, it becomes **inefficient** when applied to large-scale datasets.\n",
    "\n",
    "The amount of memory required grows **linearly** with the number of customers, and recomputing distinct counts from stored data can become **very expensive** in terms of both time and system resources.\n",
    "\n",
    "### Solution: The HyperLogLog Algorithm (HLL)\n",
    "\n",
    "To perform this task efficiently, we implemented the **probabilistic algorithm [HyperLogLog(HLL)](https://en.wikipedia.org/wiki/HyperLogLog)**, designed to **estimate the cardinality** (number of distinct elements) in large datasets.\n",
    "\n",
    "The HyperLogLog algorithm can estimate cardinalities on the order of 10⁹ elements with a **relative error below 2%**, while using only about **1.5 kB of memory**.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "In **real-time analytics systems**, where millions of events may arrive every minute, storing and maintaining exact counts of unique elements quickly becomes impractical.\n",
    "\n",
    "Instead of storing every individual customer identifier, HyperLogLog(HLL):\n",
    "\n",
    "1. **Applies a hash function** to each incoming `CustomerID` into a value;  \n",
    "2. **Updates a set of registers** represent the overall distribution of those hashes.\n",
    "\n",
    "This let the algorithm estimate the **number of unique costumers** observed so far, with a small and controllable margin of error determined by the **precision parameter `p`**.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "The main advantage of HyperLogLog lies in its **memory efficiency** and **processing speed**:\n",
    "\n",
    "- Uses a **fixed amount of memory**, regardless of the stream size;  \n",
    "- Processes each incoming event in **constant or near-constant time**;  \n",
    "- Maintains **high accuracy with minimal computational cost**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e324615",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 3. Brief History and literature review of the problem and methods/algorithms [1,5 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003888c",
   "metadata": {},
   "source": [
    "The problem of efficiently counting distinct elements in large datasets has long been a central challenge in data processing and database systems.  \n",
    "Early approaches relied on exact methods, which required storing all unique identifiers in memory or on disk.  \n",
    "While these techniques are straightforward, their **space complexity grows linearly** with the number of unique elements, making them impractical for large-scale or streaming environments where data arrives continuously and in massive volumes.\n",
    "\n",
    "In the early 1980s, **Philippe Flajolet and G. Nigel Martin** introduced the [Flajolet–Martin (FM) algorithm](https://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf), one of the first probabilistic algorithms for approximate distinct counting.  \n",
    "Their method relied on hashing each element and observing the position of the least significant 1-bit in the binary representation of the hash values.  \n",
    "The expected position of this bit could be used to estimate the logarithm of the cardinality of the dataset.  \n",
    "Although revolutionary, the original FM algorithm exhibited high variance and limited accuracy for large datasets.\n",
    "This original algorithm used only a global counter to store the highest value of the first bit position, 1, that is, the highest number of consecutive leading zeros observed in the hashes.\n",
    "The problem is that this variable had a very high variance. Therefore, just a single extreme value can drastically change the result.\n",
    "\n",
    "\n",
    "To improve the precision of probabilistic counting, **Flajolet et al.** later proposed the **LogLog** algorithm and, subsequently, the [HyperLogLog (HLL)](https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf) algorithm in 2007.  \n",
    "The HyperLogLog introduced a refined estimator based on the **harmonic mean** of multiple sub-estimators (called registers) and incorporated a **bias-correction constant** through the concept of **stochastic averaging**.  \n",
    "This design reduced the **relative standard error (RSE)** to approximately \\(1.04 / \\sqrt{m}\\), where \\(m = 2^p\\) is the number of registers.  \n",
    "Instead of maintaining a single global counter, the hash space is divided into \\(m\\) disjoint subsets (or buckets), and an independent estimate is computed for each subset.\n",
    "\n",
    "The HyperLogLog algorithm thus achieved an elegant balance between **accuracy**, **computational efficiency**, and **memory usage**.\n",
    "\n",
    "HLL thus provided an elegant balance between **accuracy**, **computational efficiency**, and **memory usage**.\n",
    "\n",
    "Over time, the HyperLogLog algorithm became one of the most widely adopted techniques for large-scale analytics.  \n",
    "It is currently implemented in major data systems such as **Google BigQuery**, **Redis**, **Apache Spark**, and **PostgreSQL**, where it supports real-time analytics and streaming queries.  \n",
    "Its **merge** property — the ability to combine multiple estimators into a single global one — makes it particularly suitable for **distributed architectures** and **parallel computation** environments.\n",
    "\n",
    "Beyond web analytics and online systems, HyperLogLog is used in **network monitoring**, **fraud detection**, **ad impression counting**, and **data deduplication**.  \n",
    "Its efficiency lies in providing **near-constant memory usage** and **fast incremental updates**, allowing accurate estimation of distinct elements in data streams that would otherwise be too large to store or process exactly.\n",
    "\n",
    "HyperLogLog represents a key milestone in the evolution of probabilistic counting algorithms, combining solid mathematical foundations with proven scalability and practical relevance in modern Big Data applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889a980",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 4. About the main method/algorithm used [1,5 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52795c65",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 5. Python imports and global configurations [0,5 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f3deb",
   "metadata": {},
   "source": [
    "### Install and import the necessary libraries to compute the Bayesian Network and perform other methods  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5177dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install ucimlrepo\n",
    "\n",
    "import hashlib\n",
    "import matplotlib\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb739aae",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 6. Dataset and variables explanation [1,5 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91985f2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5703771",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 7. Main code as possible solution to the problem [1,5 valor] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49605a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data = fetch_ucirepo(id=352)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a15554",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 8. Analysis of Example 1 [3,0 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7810c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 9. Analysis of Example 2 [3,0 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e821172",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 10. Pros and cons of the approach [2,0 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60974d68",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 11. Future improvements [2,0 valor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1eb04",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <br><br>\n",
    "    <p style=\"font-size: 40px;\">References [1,0 valor]</p>\n",
    "</div>\n",
    "<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
